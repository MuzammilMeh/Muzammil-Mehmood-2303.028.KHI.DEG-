{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7343c19a-1474-4a49-b32d-b8868e30386c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import pyspark\n",
    "from IPython.display import clear_output, display\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    avg,\n",
    "    col,\n",
    "    max,\n",
    "    min,\n",
    "    udf,\n",
    ")\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a90b92c0-ef1b-40e8-8b00-9ee033067515",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/19 08:24:34 WARN Utils: Your hostname, all-MS-7D35 resolves to a loopback address: 127.0.1.1; using 192.168.1.142 instead (on interface enp2s0)\n",
      "23/05/19 08:24:34 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/05/19 08:24:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"TitanicData\").getOrCreate()\n",
    "# Read the CSV file into a DataFrame\n",
    "df_pyspark = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").option(\"header\", \"false\").csv(\"data/titanic.csv\")\n",
    "# Define the column names of the Titanic dataset\n",
    "column_names = ['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked','Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152e8586-2fec-4c95-8f39-fda1ef175ba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      " |-- Timestamp: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Assign the column names to the DataFrame\n",
    "df_pyspark = df_pyspark.toDF(*column_names)\n",
    "# Display the DataFrame schema\n",
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d9709b-396a-4ef0-9924-1606760909fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked',\n",
       " 'Timestamp']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the column names\n",
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6b02c38-558d-4baa-86ef-94ac556031c5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Braund, Mr. Owen ...|\n",
      "|Cumings, Mrs. Joh...|\n",
      "|Heikkinen, Miss. ...|\n",
      "|Futrelle, Mrs. Ja...|\n",
      "|Allen, Mr. Willia...|\n",
      "|    Moran, Mr. James|\n",
      "|McCarthy, Mr. Tim...|\n",
      "|Palsson, Master. ...|\n",
      "|Johnson, Mrs. Osc...|\n",
      "|Nasser, Mrs. Nich...|\n",
      "|Sandstrom, Miss. ...|\n",
      "|Bonnell, Miss. El...|\n",
      "|Saundercock, Mr. ...|\n",
      "|Andersson, Mr. An...|\n",
      "|Vestrom, Miss. Hu...|\n",
      "|Hewlett, Mrs. (Ma...|\n",
      "|Rice, Master. Eugene|\n",
      "|Williams, Mr. Cha...|\n",
      "|Vander Planke, Mr...|\n",
      "|Masselmani, Mrs. ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(\"Name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d84ac32e-5ed4-4a1d-9544-59c7bac93477",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/05/19 08:27:41 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "|summary|      PassengerId|            Pclass|               Age|             SibSp|              Parch|             Fare|\n",
      "+-------+-----------------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "|  count|              891|               891|               714|               891|                891|              891|\n",
      "|   mean|            446.0| 2.308641975308642|29.679271708683473|0.5230078563411896|0.38159371492704824| 32.2042079685746|\n",
      "| stddev|257.3538420152301|0.8360712409770491|14.536482769437564|1.1027434322934315| 0.8060572211299488|49.69342859718089|\n",
      "|    min|                1|                 1|                 0|                 0|                  0|              0.0|\n",
      "|    max|              891|                 3|                80|                 8|                  6|         512.3292|\n",
      "+-------+-----------------+------------------+------------------+------------------+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_cols = [col for col, dtype in df_pyspark.dtypes if dtype in ['int', 'double']]\n",
    "num_stats = df_pyspark.select(num_cols).describe().drop(\"Survived\")\n",
    "num_stats.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ff233ab-e5fc-4467-b0bf-a8d9bc09e88a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum values:\n",
      "Row(PassengerId=1, Pclass=1, Age=0, Fare=0.0, SibSp=0, Parch=0, Embarked='C')\n",
      "Maximum values:\n",
      "Row(PassengerId=891, Pclass=3, Age=80, Fare=512.3292, SibSp=8, Parch=6, Embarked='S')\n",
      "Average values:\n",
      "Row(PassengerId=446.0, Pclass=2.308641975308642, Age=29.679271708683473, Fare=32.2042079685746, SibSp=0.5230078563411896, Parch=0.38159371492704824, Embarked=None)\n"
     ]
    }
   ],
   "source": [
    "numeric_columns = df_pyspark.select(\"PassengerId\", \"Pclass\", \"Age\", \"Fare\", \"SibSp\", \"Parch\", \"Embarked\").columns\n",
    "min_values = df_pyspark.select(numeric_columns).agg(*(min(c).alias(c) for c in numeric_columns)).collect()[0]\n",
    "max_values = df_pyspark.select(numeric_columns).agg(*(max(c).alias(c) for c in numeric_columns)).collect()[0]\n",
    "avg_values = df_pyspark.select(numeric_columns).agg(*(avg(c).alias(c) for c in numeric_columns)).collect()[0]\n",
    "print(\"Minimum values:\")\n",
    "print(min_values)\n",
    "print(\"Maximum values:\")\n",
    "print(max_values)\n",
    "print(\"Average values:\")\n",
    "print(avg_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "519a50c0-3396-4874-b1e3-b83bb5037d11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|          Timestamp|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------------+\n",
      "|          1|       1|     1|Braund, Mr. Owen ...|  mal1|  22|    1|    0|       A/5 21171|   7.25| null|       1|2020-01-01 13:45:25|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|femal1|  38|    1|    0|        PC 17599|71.2833|  C85|       1|2020-01-01 13:44:48|\n",
      "|          3|       1|     1|Heikkinen, Miss. ...|femal1|  26|    0|    0|STON/O2. 3101282|  7.925| null|       1|2020-01-01 13:38:11|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|femal1|  35|    1|    0|          113803|   53.1| C123|       1|2020-01-01 13:32:00|\n",
      "|          5|       1|     1|Allen, Mr. Willia...|  mal1|  35|    0|    0|          373450|   8.05| null|       1|2020-01-01 13:36:30|\n",
      "|          6|       1|     1|    Moran, Mr. James|  mal1|null|    0|    0|          330877| 8.4583| null|       1|2020-01-01 13:31:39|\n",
      "|          7|       1|     1|McCarthy, Mr. Tim...|  mal1|  54|    0|    0|           17463|51.8625|  E46|       1|2020-01-01 13:37:31|\n",
      "|          8|       1|     1|Palsson, Master. ...|  mal1|   2|    3|    1|          349909| 21.075| null|       1|2020-01-01 13:49:08|\n",
      "|          9|       1|     1|Johnson, Mrs. Osc...|femal1|  27|    0|    2|          347742|11.1333| null|       1|2020-01-01 13:33:42|\n",
      "|         10|       1|     1|Nasser, Mrs. Nich...|femal1|  14|    1|    0|          237736|30.0708| null|       1|2020-01-01 13:32:53|\n",
      "|         11|       1|     1|Sandstrom, Miss. ...|femal1|   4|    1|    1|         PP 9549|   16.7|   G6|       1|2020-01-01 13:32:23|\n",
      "|         12|       1|     1|Bonnell, Miss. El...|femal1|  58|    0|    0|          113783|  26.55| C103|       1|2020-01-01 13:30:12|\n",
      "|         13|       1|     1|Saundercock, Mr. ...|  mal1|  20|    0|    0|       A/5. 2151|   8.05| null|       1|2020-01-01 13:33:34|\n",
      "|         14|       1|     1|Andersson, Mr. An...|  mal1|  39|    1|    5|          347082| 31.275| null|       1|2020-01-01 13:30:20|\n",
      "|         15|       1|     1|Vestrom, Miss. Hu...|femal1|  14|    0|    0|          350406| 7.8542| null|       1|2020-01-01 13:41:17|\n",
      "|         16|       1|     1|Hewlett, Mrs. (Ma...|femal1|  55|    0|    0|          248706|   16.0| null|       1|2020-01-01 13:34:22|\n",
      "|         17|       1|     1|Rice, Master. Eugene|  mal1|   2|    4|    1|          382652| 29.125| null|       1|2020-01-01 13:41:55|\n",
      "|         18|       1|     1|Williams, Mr. Cha...|  mal1|null|    0|    0|          244373|   13.0| null|       1|2020-01-01 13:39:35|\n",
      "|         19|       1|     1|Vander Planke, Mr...|femal1|  31|    1|    0|          345763|   18.0| null|       1|2020-01-01 13:39:38|\n",
      "|         20|       1|     1|Masselmani, Mrs. ...|femal1|null|    0|    0|            2649|  7.225| null|       1|2020-01-01 13:36:56|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "str_columns = [\"Sex\", \"Pclass\", \"Survived\", \"Embarked\"]\n",
    "\n",
    "def change_last_letter_after_space(word):\n",
    "    if word is not None:\n",
    "        words = word.split()\n",
    "        for i in range(len(words)):\n",
    "            words[i] = words[i][:-1] + \"1\"\n",
    "        return \" \".join(words)\n",
    "    return word\n",
    "\n",
    "change_last_letter_udf = udf(change_last_letter_after_space, StringType())\n",
    "\n",
    "for column in str_columns:\n",
    "    if column == \"Pclass\" or column == \"Survived\":\n",
    "        df_pyspark = df_pyspark.withColumn(column, col(column).cast(StringType()))\n",
    "    df_pyspark = df_pyspark.withColumn(column, change_last_letter_udf(col(column)))\n",
    "\n",
    "df_pyspark.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d5e1d48-f1ec-4bb6-a532-6f643f7b30b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort DataFrame by the first column\n",
    "sorted_df = df.orderBy(df.columns[0])\n",
    "# Save the sorted DataFrame to Parquet file\n",
    "sorted_df.write.parquet(\"./sorted_titanic/titanic.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1279eda2-eb9e-45b4-a462-b20312d6dbe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
